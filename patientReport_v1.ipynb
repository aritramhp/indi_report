{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare a Report for an individual patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Environment setup\n",
    ">> Install anaconda and follow the steps in Anaconda Prompt:\n",
    ">> - `conda create --name indi_report --file requirements.txt`\n",
    ">> - `conda activate indi_report`\n",
    ">> - `python -m ipykernel install --user --name=indi_report`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference DB\n",
    ">> Execute IMNGS2 / NGSToolkit on the reference samples: KORA-Healthy, KORA-Obese, and Student cohort -> Generate zOTU table\n",
    ">>\n",
    ">> Execute Rhea:\n",
    ">> - Normalization, Alpha diverisity, and Taxonomy binning on KORA-Healthy, KORA-Obese, and Students cohort\n",
    ">> - Beta diversity on KORA-Healthy and Students cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Steps to follow,\n",
    "> 1) Run IMNGS2 / NGSToolkit on the samples  -> Generate zOTU table\n",
    "> 2) Run Rhea -- Alpha diversity, Taxonomic binning\n",
    "> 3)   Get following files and move them into the input directory:\n",
    ">> - alpha-diversity.tab\n",
    ">> - 1.Phyla.all.tab\n",
    ">> - 5.Genera.all.tab\n",
    "> 4) In addtion, also store the metafile in the input directory\n",
    "> 5) Execute the following codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline      # show inline plot\n",
    "import os\n",
    "import pandas as pd\n",
    "# import random\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "matplotlib.use('Agg')   # restrict showing inline plots \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm\n",
    "# import statistics \n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "from fpdf import FPDF\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from fpdf.fonts import FontFace\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set inputs [Modify]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input directory\n",
    "input_dir = 'test_data1'\n",
    "\n",
    "# set input filenames\n",
    "alpha_div_filename  = 'alpha-diversity.tab'\n",
    "phylum_filename = '1.Phyla.all.tab'\n",
    "genera_filename = '5.Genera.all.tab'\n",
    "# this is a tab-separated file with six columns -- \"OrderNumber\", \"SampleName\", \"Age\", \"SampleType\", \"SamplingDate\", \"Screening-ID\"\n",
    "# OrderNumber: \n",
    "# SampleName: Name of the samples\n",
    "# Age: Number\n",
    "# SampleType: Usually \"Stool\"\n",
    "# SamplingDate: dd.mm.yy format\n",
    "# Screening-ID: \n",
    "info_filename = 'info_HH.tab'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check ref database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of KORA samples: 1562\n",
      "No. of Student samples: 295\n"
     ]
    }
   ],
   "source": [
    "# input files for the samples\n",
    "alpha_div = os.path.join(input_dir,alpha_div_filename)\n",
    "tax_phyla = os.path.join(input_dir,phylum_filename)\n",
    "tax_phyla = os.path.join(input_dir,genera_filename)\n",
    "info_file = os.path.join(input_dir,info_filename)\n",
    "\n",
    "# this is a tab-separated file with two columns -- \"former_name\" and \"Genus\"\n",
    "# this file contains mapping between unknown GOTUs with a name\n",
    "# Don't change the name ('gotu_names.tab')\n",
    "gotu_names = os.path.join(input_dir,'gotu_names.tab')\n",
    "\n",
    "# Set reference directory\n",
    "ref_db = 'ref_db'\n",
    "ref_alpha = os.path.join(ref_db, 'alpha-diversity.tab')\n",
    "ref_phyla = os.path.join(ref_db, '1.Phyla.all.tab')\n",
    "ref_genera = os.path.join(ref_db, '5.Genera.all.tab')\n",
    "ref_func = os.path.join(ref_db, 'genera_func_2_languages_2024-07-11.txt')      # Save the tab file in UTF-16 unicode\n",
    "ref_clade = os.path.join(ref_db,'clade.tab')\n",
    "df_alpha = pd.read_csv(ref_alpha,sep='\\t').set_index('Unnamed: 0')\n",
    "df_phyla = pd.read_csv(ref_phyla,sep='\\t').set_index('Unnamed: 0')\n",
    "df_genera = pd.read_csv(ref_genera,sep='\\t').set_index('Unnamed: 0')\n",
    "assert set(df_alpha.index.to_list()) == set(df_phyla.columns.to_list()), 'Sample mismatch found in alpha diversity and phyla'\n",
    "assert set(df_alpha.index.to_list()) == set(df_genera.columns.to_list()), 'Sample mismatch found in alpha diversity and genera'\n",
    "assert set(df_phyla.columns.to_list()) == set(df_genera.columns.to_list()), 'Sample mismatch found in phyla and genera'\n",
    "kora_sample = [c for c in df_alpha.index.to_list() if c.startswith('KORA')]\n",
    "std_sample = [c for c in df_alpha.index.to_list() if c.startswith('std')]\n",
    "print('No. of KORA samples: {}\\nNo. of Student samples: {}'.format(len(kora_sample), len(std_sample)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider the samples present in reference dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of diabetic: 123\n",
      "No. of obese: 1126\n",
      "No. of cancer: 128\n",
      "No. of healthy: 436\n",
      "No. of samples to analyze: 5\n",
      "Name of the samples: ['305-5-16641', '304-4-78826', '302-2-89334', '306-6-83608', '301-1-59020']\n",
      "healthyKORA + Student: 731\n"
     ]
    }
   ],
   "source": [
    "# KORA metadata: list of samples from each category\n",
    "kora_metadata =os.path.join('KORA_metadata','gesamt_2032020.xlsx')\n",
    "df_metadata = pd.read_excel(kora_metadata,sheet_name='Analysiert',engine='openpyxl').set_index('Aritra_sampleID')\n",
    "diabet = df_metadata[df_metadata['u3tglukfasta'] >= 125].index.to_list()\n",
    "obese = df_metadata[df_metadata['u3tbmi'] >= 25].index.to_list()\n",
    "cancer = df_metadata[df_metadata['lca_n_sf14'] != 0].index.to_list()\n",
    "healthy = set(df_metadata.index.to_list()).difference(set(diabet+obese+cancer))\n",
    "\n",
    "# KORA diabet \n",
    "kora_diabet = list(set(kora_sample).intersection(set(diabet)))\n",
    "print('No. of diabetic: {}'.format(len(kora_diabet)))\n",
    "# KORA obese\n",
    "kora_obese = list(set(kora_sample).intersection(set(obese)))\n",
    "print('No. of obese: {}'.format(len(kora_obese)))\n",
    "# KORA obese\n",
    "kora_cancer = list(set(kora_sample).intersection(set(cancer)))\n",
    "print('No. of cancer: {}'.format(len(kora_cancer)))\n",
    "# KORA healthy\n",
    "kora_healthy = list(set(kora_sample).intersection(set(healthy)))\n",
    "print('No. of healthy: {}'.format(len(kora_healthy)))\n",
    "\n",
    "# check if all the current samples are present\n",
    "df_current_sample = pd.read_csv(alpha_div,sep='\\t')\n",
    "df_current_sample['Unnamed: 0'] = df_current_sample['Unnamed: 0'].str.replace('-withoutSpikes','')\n",
    "df_current_sample = df_current_sample.set_index('Unnamed: 0')\n",
    "current_sample = [c for c in df_current_sample.index if not c.startswith('KORA') and not c.startswith('std')]\n",
    "df_sampleinfo = pd.read_csv(info_file,sep='\\t',keep_default_na=False)\n",
    "# assert set(current_sample) == set(df_sampleinfo.SampleName.to_list()), 'Mismatch found in the samples provided with the metadata!'\n",
    "assert set(df_sampleinfo.SampleName.to_list()).issubset(set(current_sample)), 'Mismatch found in the samples provided with the metadata!'\n",
    "current_sample = df_sampleinfo.SampleName.to_list()\n",
    "print('No. of samples to analyze: {}'.format(len(current_sample)))\n",
    "print('Name of the samples: {}'.format(current_sample))\n",
    "print('healthyKORA + Student: {}'.format(len(kora_healthy+std_sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Alpha diversity and Taxonomy binning of Current samples with the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_data1\\\\Phyla.sample.tab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m alpha_div, tax_phyla, tax_genera \u001b[38;5;241m=\u001b[39m \u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_with_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43mref_phyla\u001b[49m\u001b[43m,\u001b[49m\u001b[43mref_genera\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMerged alpha diversity: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(alpha_div))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMerged phyla: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(tax_phyla))\n",
      "File \u001b[1;32mc:\\Users\\Neuhaus\\Downloads\\indi_report-main\\functions.py:52\u001b[0m, in \u001b[0;36mmerge_with_ref\u001b[1;34m(ref_alpha, ref_phyla, ref_genera, input_dir)\u001b[0m\n\u001b[0;32m     49\u001b[0m alpha_diversity \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha-diversity_ref_current.tab\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     50\u001b[0m df3\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha-diversity_ref_current.tab\u001b[39m\u001b[38;5;124m'\u001b[39m),sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 52\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPhyla.sample.tab\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(ref_phyla,sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     54\u001b[0m df3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df1, df2, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\indi_report\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\indi_report\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\indi_report\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\indi_report\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\indi_report\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_data1\\\\Phyla.sample.tab'"
     ]
    }
   ],
   "source": [
    "import functions\n",
    "alpha_div, tax_phyla, tax_genera = functions.merge_with_ref(ref_alpha,ref_phyla,ref_genera,input_dir)\n",
    "print('Merged alpha diversity: {}'.format(alpha_div))\n",
    "print('Merged phyla: {}'.format(tax_phyla))\n",
    "print('Merged genera: {}'.format(tax_genera))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Alpha diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305-5-16641\n",
      "304-4-78826\n",
      "302-2-89334\n",
      "306-6-83608\n",
      "301-1-59020\n"
     ]
    }
   ],
   "source": [
    "import functions\n",
    "\n",
    "for sample in current_sample:            \n",
    "    quartile = functions.alpha_diversity(input_dir, sample, alpha_div, [('std',std_sample),('healthy',kora_healthy),('obese',kora_obese)],'Richness')\n",
    "    with open(os.path.join(input_dir,sample,'report_EN.txt'),'w') as fp_en, open(os.path.join(input_dir,sample,'report_DE.txt'),'w') as fp_de:\n",
    "        for c, p in quartile:\n",
    "            fp_en.write(c+':'+p+'\\n')\n",
    "            p_de = 'unteres Quartil' if p=='lower quartile' else 'höheres Quartil' if p=='upper quartile' else 'mittleres Quartil'\n",
    "            fp_de.write(c+':'+p_de+'\\n')\n",
    "    print(sample)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare iTOL annotation file \n",
    "> Next follow the steps below,\n",
    "> 1. Upload `individual_patient_report.nwk`\n",
    "> 2. Upload iTOL annotation files\n",
    "> 3. Change settings:\n",
    ">> - Basic: Labels --> Hide\n",
    ">> - Advanced: Tree scale box --> Hide\n",
    "> 4. Export: \n",
    ">> - Format: png\n",
    ">> - Resolution: 200 dpi\n",
    ">> - Export area: Full screen\n",
    ">> - File name: `sampletree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305-5-16641\n",
      "304-4-78826\n",
      "302-2-89334\n",
      "306-6-83608\n",
      "301-1-59020\n"
     ]
    }
   ],
   "source": [
    "import functions\n",
    "\n",
    "# df_sampleinfo = pd.read_csv(info_file,sep='\\t')\n",
    "df_itol = df_sampleinfo.set_index('SampleName')\n",
    "abun_table = tax_phyla\n",
    "for sname in df_itol.index:\n",
    "    print(sname)\n",
    "    samplelist = kora_healthy + std_sample + [sname]\n",
    "    output_file = os.path.join(input_dir,sname,'itol1_branch.txt')\n",
    "    with open(output_file, 'w') as fp:\n",
    "        fp.write('TREE_COLORS\\nSEPARATOR COMMA\\nDATA\\nOROOT,clade,#000000,normal,3\\n')\n",
    "    output_file = os.path.join(input_dir,sname,'itol2_clade.txt')\n",
    "    functions.clade_strip(sname, ref_clade, output_file)\n",
    "    output_file = os.path.join(input_dir,sname,'itol3_phylum.txt')\n",
    "    functions.stacked_bar_itol(abun_table, sname, samplelist, output_file)\n",
    "    output_file = os.path.join(input_dir,sname,'itol4_marksample')\n",
    "    ref_sample = kora_healthy + std_sample\n",
    "    similar_sample = functions.mark_sample(sname,abun_table,ref_sample,output_file)\n",
    "    clade_data = pd.read_table(ref_clade, sep='\\t')\n",
    "    clade = clade_data[clade_data['sample']==similar_sample]['clade'].to_list()[0]\n",
    "    with open(os.path.join(input_dir,sname,'report_EN.txt'),'a') as fp_en, open(os.path.join(input_dir,sname,'report_DE.txt'),'a') as fp_de:\n",
    "        fp_en.write('cluster:'+str(clade)+'\\n')\n",
    "        fp_de.write('cluster:'+str(clade)+'\\n')\n",
    "        percentage = 11 if clade==1 else 39 if clade==2 else 12 if clade==3 else 38\n",
    "        fp_en.write('percentage:'+str(percentage)+'\\n')\n",
    "        fp_de.write('percentage:'+str(percentage)+'\\n')\n",
    "        distinct_genera = 'Prevotella-9' if clade==1 else 'Bacteroides' if clade==2 else 'Ruminococcaceae_UGC-002' if clade==3 else 'Ruminococcus'\n",
    "        fp_en.write('distinguish:'+distinct_genera+'\\n')\n",
    "        fp_de.write('distinguish:'+distinct_genera+'\\n')\n",
    "\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phylum barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305-5-16641\n",
      "304-4-78826\n",
      "302-2-89334\n",
      "306-6-83608\n",
      "301-1-59020\n"
     ]
    }
   ],
   "source": [
    "import functions\n",
    "\n",
    "abun_table = tax_phyla\n",
    "abun_data = pd.read_table(abun_table, sep='\\t').set_index('Unnamed: 0')\n",
    "df_itol = df_sampleinfo.set_index('SampleName')\n",
    "colors = {'p__Actinobacteriota':'#f5e4ea','p__Bacteroidota':'#94ac7c','p__Firmicutes':'#847cb6','p__Fusobacteriota':'#a28145',\n",
    "          'p__Proteobacteria':'#e9c334','p__Verrucomicrobiota':'#7b98d1'}\n",
    "for sname in df_itol.index:\n",
    "    print(sname)\n",
    "    hlthy2 = list(set(abun_data.columns.to_list()).intersection(set(healthy)))\n",
    "    abun_data['avg_old'] = abun_data[hlthy2].mean(axis=1)\n",
    "    abun_data['avg_young'] = abun_data[std_sample].mean(axis=1)\n",
    "    df = abun_data[[sname,'avg_young','avg_old']]\n",
    "    df_barplot = df.loc[list(colors.keys()),:]\n",
    "    df_barplot = df_barplot.T\n",
    "    # Color\n",
    "    clr = [colors[i] if i in colors.keys() else '#bcbcbc' for i in df_barplot.columns]\n",
    "    # remove phylum tag from the names\n",
    "    df_barplot.columns = df_barplot.columns.str.replace(\"p__\", \"\")\n",
    "    # rename phylum with preferred name\n",
    "    df_barplot = df_barplot.rename(columns={'Firmicutes':'Bacillota'})\n",
    "    df_barplot = df_barplot.reindex(sorted(df_barplot.columns), axis=1)\n",
    "    df_barplot['Others'] = df.loc[list(set(df.index.to_list()).difference(set(list(colors.keys())))),:].sum(axis='index').to_list()\n",
    "    clr = clr+['#bcbcbc']\n",
    "    xticks = ['Sample','Healthy young','Healthy old']\n",
    "    ylabel = 'Relative abundance (%)'\n",
    "    figfile = os.path.join(input_dir, sname,'phylum_EN.jpg')\n",
    "    functions.stacked_bar_phylum(df_barplot,clr,xticks,ylabel,figfile)\n",
    "    df_barplot = df_barplot.rename(columns={'Others':'Andere'})\n",
    "    xticks = ['Probe','Gesund, jung','Gesund, alt']\n",
    "    ylabel = 'Relative Abundanz (%)'\n",
    "    figfile = os.path.join(input_dir, sname,'phylum_DE.jpg')\n",
    "    functions.stacked_bar_phylum(df_barplot,clr,xticks,ylabel,figfile)\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot: Bacillota/Bacteroidota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305-5-16641\n",
      "304-4-78826\n",
      "302-2-89334\n",
      "306-6-83608\n",
      "301-1-59020\n"
     ]
    }
   ],
   "source": [
    "import functions\n",
    "\n",
    "abun_table = tax_phyla\n",
    "abun_data = pd.read_table(abun_table, sep='\\t').set_index('Unnamed: 0')\n",
    "df_itol = df_sampleinfo.set_index('SampleName')\n",
    "for sname in df_itol.index:\n",
    "    print(sname)\n",
    "    hlthy2 = list(set(abun_data.columns.to_list()).intersection(set(healthy)))\n",
    "    abun_data['avg_old'] = abun_data[hlthy2].mean(axis=1)\n",
    "    abun_data['avg_young'] = abun_data[std_sample].mean(axis=1)\n",
    "    \n",
    "    fb_list, cat_class, quartile = [], [], []\n",
    "    for cat, cat_sample in [('healthy_young',std_sample),('healthy_old',hlthy2)]:\n",
    "        cat_fb = abun_data[cat_sample].T['p__Firmicutes']/abun_data[cat_sample].T['p__Bacteroidota'].to_list()\n",
    "        fb_list.extend(cat_fb)\n",
    "        cat_class.extend([cat]*len(cat_fb))\n",
    "    sample_f_by_b = abun_data[sname].T['p__Firmicutes']/abun_data[sname].T['p__Bacteroidota']\n",
    "    df_fb = pd.DataFrame(zip(fb_list,cat_class), columns=['f_by_b','class'])\n",
    "    figfile = os.path.join(input_dir, sname,'f_b_ratio_EN.jpg')\n",
    "    functions.box_plot(df_fb,sample_f_by_b,['Healthy young','Healthy old'],'Sample',figfile)\n",
    "    figfile = os.path.join(input_dir, sname,'f_b_ratio_DE.jpg')\n",
    "    functions.box_plot(df_fb,sample_f_by_b,['Gesund, jung','Gesund, alt'],'Probe',figfile)\n",
    "    # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_genus = {'LachnospiraceaeNK4A136group':'NK4A136 in Lachnospiraceae',\n",
    "                'ChristensenellaceaeR-7group':'R-7 in Christensenellaceae',\n",
    "                'NK4A214group':'NK4A214 in Ruminococcaceae',\n",
    "                'UCG-002':'UGC-002 in Ruminococcaceae',\n",
    "                'Eubacteriumeligensgroup':'Eubacterium-eligens-group',\n",
    "                'Eubacteriumsiraeumgroup':'Eubacterium-siraeum-group',\n",
    "                'PrevotellaceaeNK3B31group':'NK3B31 in Prevotellaceae',\n",
    "                'UCG-005':'UCG-005 in Ruminococcaceae',\n",
    "                'Eubacteriumhalliigroup':'Eubacterium-hallii-group',\n",
    "                'LachnospiraceaeND3007group':'ND3007 in Lachnospiraceae',\n",
    "                'Ruminococcusgnavusgroup':'Ruminococcus-gnavus-group',\n",
    "                'Bacteroides pectinophilus group':'Bacteroides-pectinophilus-group',\n",
    "                'Christensenellaceae R-7 group':'R-7 in Christensenellaceae ',\n",
    "                'Lachnospiraceae NK4A136 group':'NK4A214 in Ruminococcaceae',\n",
    "                'Rikenellaceae RC9 gut group':'Rikenellaceae-RC9-gut-group',\n",
    "                'unknown_ Clostridia UCG-014':'Clostridia UCG-014',\n",
    "                'unknown_ Clostridia vadinBB60 group':'Clostridia-vadinBB60-group',\n",
    "                'unknown_ Desulfovibrionaceae':'Taxon in Desulfovibrionaceae',\n",
    "                'unknown_ Eubacterium coprostanoligenes group':'Eubacterium-coprostanoligenes-group',\n",
    "                'unknown_ Gastranaerophilales':'Taxon in Gastranaerophilales',\n",
    "                'unknown_ Lachnospiraceae':'Taxon in  Lachnospiraceae',\n",
    "                'unknown_ Muribaculaceae':'Taxon in  Muribaculaceae',\n",
    "                'unknown_ Rhodospirillales':'Taxon in  Rhodospirillales',\n",
    "                'unknown_ Ruminococcaceae':'Taxon in Ruminococcaceae',\n",
    "                'Lachnospiraceae UCG-001':'UCG-001 in Lachnospiraceae',\n",
    "                'LachnospiraceaeUCG-001':'UCG-001 in Lachnospiraceae',\n",
    "                'UCG-003':'UCG-003 in Lachnospiraceae',\n",
    "                'Ruminococcustorquesgroup':'Ruminococcus torques group',\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genera barplot (Top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305-5-16641\n",
      "304-4-78826\n",
      "302-2-89334\n",
      "306-6-83608\n",
      "301-1-59020\n"
     ]
    }
   ],
   "source": [
    "import functions\n",
    "\n",
    "abun_table = tax_genera\n",
    "abun_data = pd.read_table(abun_table, sep='\\t').set_index('Unnamed: 0')\n",
    "df_itol = df_sampleinfo.set_index('SampleName')\n",
    "colors17= ['#3eb489','#ff6ec7','#ffd12b','#03324a','#16621c','#5f2e4c','#f9584b','#596fff','#81dd4d','#e6b710','#ff8980','#00FFFD','#b5db52','#FF6900','#c90076','#2ffd51','#ff8933']\n",
    "\n",
    "# Unknown GOTUs\n",
    "if os.path.isfile(gotu_names):\n",
    "    df_gotu = pd.read_csv(gotu_names,sep='\\t',index_col='former_name')\n",
    "    gotu_dict = df_gotu.to_dict()['Genus']\n",
    "else:\n",
    "    gotu_dict = {}\n",
    "    \n",
    "for sname in df_itol.index:\n",
    "    # KORA-Healty\n",
    "    print(sname)\n",
    "    hlthy2 = list(set(abun_data.columns.to_list()).intersection(set(healthy)))\n",
    "    abun_data['avg_old'] = abun_data[hlthy2].mean(axis=1)\n",
    "    # Student\n",
    "    abun_data['avg_young'] = abun_data[std_sample].mean(axis=1)\n",
    "    \n",
    "    df_avg = abun_data[[sname,'avg_young','avg_old']]\n",
    "    # print(df_avg)\n",
    "    sample_top_genus = df_avg.nlargest(1,sname).index.to_list()[0].replace('g__','')\n",
    "    with open(os.path.join(input_dir,sname,'report_EN.txt'),'a') as fp_en, open(os.path.join(input_dir,sname,'report_DE.txt'),'a') as fp_de:\n",
    "        fp_en.write('topgenus:'+sample_top_genus+'\\n')\n",
    "        fp_de.write('topgenus:'+sample_top_genus+'\\n')\n",
    "    top_old = df_avg.nlargest(10,'avg_old').index.to_list()\n",
    "    top_young = df_avg.nlargest(10,'avg_young').index.to_list()\n",
    "    top_sample = df_avg.nlargest(10,sname).index.to_list()\n",
    "    top = set(top_old).union(set(top_young)).union(set(top_sample))\n",
    "    df_barplot = df_avg.loc[list(top)].sort_values('avg_young', ascending=False)\n",
    "    # df_barplot.loc['others'] = df_avg.loc[list(set(df_avg.index.to_list()).difference(top)),:].sum(axis='index').to_list()\n",
    "\n",
    "    df_barplot = df_barplot.T\n",
    "    # remove phylum tag from the names\n",
    "    df_barplot.columns = df_barplot.columns.str.replace(\"g__\", \"\")\n",
    "    # rename genus with preferred name\n",
    "    df_barplot = df_barplot.rename(columns=rename_genus)\n",
    "    df_barplot = df_barplot.reindex(sorted(df_barplot.columns), axis=1)\n",
    "    # print(df_barplot.T.sort_values(sname,axis=0))\n",
    "    df_barplot = df_barplot.T.sort_values(sname,axis=0,ascending=False).T\n",
    "    index_genera = df_barplot.columns.to_list() \n",
    "    df_barplot['Others'] = df_avg.loc[list(set(df_avg.index.to_list()).difference(top)),:].sum(axis='index').to_list()\n",
    "    # rename unknown genus with the names present in \"gotu_name.tab\"\n",
    "    df_barplot = df_barplot.rename(columns=gotu_dict)\n",
    "    # plt.subplots(figsize=(2, 10))\n",
    "    with open(os.path.join(input_dir, sname,'topGenera.pkl'), 'wb') as f:\n",
    "        pickle.dump(df_barplot.columns.to_list(), f)\n",
    "    figfile = os.path.join(input_dir, sname,'genera_EN.jpg')\n",
    "    functions.stacked_bar_genus(df_barplot,top,colors17,['Sample','Healthy young', 'Healthy old'],'Relative abundance (%)',figfile)\n",
    "    df_barplot = df_barplot.rename(columns={'Others':'Andere'})\n",
    "    figfile = os.path.join(input_dir, sname,'genera_DE.jpg')\n",
    "    functions.stacked_bar_genus(df_barplot,top,colors17,['Probe','Gesund, jung','Gesund, alt'],'Relative abundanz (%)',figfile)\n",
    "\n",
    "    # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write into PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:10: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', 'I', 8)\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:14: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  self.cell(0, 10, 'Order: '+str(self.ordernum)+' / Sample: '+str(self.samplename), 0, 0, 'R')\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:10: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', 'I', 8)\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:14: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  self.cell(0, 10, 'Order: '+str(self.ordernum)+' / Sample: '+str(self.samplename), 0, 0, 'R')\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:10: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', 'I', 8)\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:14: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  self.cell(0, 10, 'Order: '+str(self.ordernum)+' / Sample: '+str(self.samplename), 0, 0, 'R')\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:10: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', 'I', 8)\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:14: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  self.cell(0, 10, 'Order: '+str(self.ordernum)+' / Sample: '+str(self.samplename), 0, 0, 'R')\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:10: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', 'I', 8)\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:14: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  self.cell(0, 10, 'Order: '+str(self.ordernum)+' / Sample: '+str(self.samplename), 0, 0, 'R')\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:10: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', 'I', 8)\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:14: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  self.cell(0, 10, 'Order: '+str(self.ordernum)+' / Sample: '+str(self.samplename), 0, 0, 'R')\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:10: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', 'I', 8)\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:14: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  self.cell(0, 10, 'Order: '+str(self.ordernum)+' / Sample: '+str(self.samplename), 0, 0, 'R')\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:10: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', 'I', 8)\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:14: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  self.cell(0, 10, 'Order: '+str(self.ordernum)+' / Sample: '+str(self.samplename), 0, 0, 'R')\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:10: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', 'I', 8)\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:14: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  self.cell(0, 10, 'Order: '+str(self.ordernum)+' / Sample: '+str(self.samplename), 0, 0, 'R')\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:10: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', 'I', 8)\n",
      "C:\\Users\\Aritra\\AppData\\Local\\Temp\\ipykernel_1016\\362285677.py:14: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  self.cell(0, 10, 'Order: '+str(self.ordernum)+' / Sample: '+str(self.samplename), 0, 0, 'R')\n"
     ]
    }
   ],
   "source": [
    "class PDF(FPDF):\n",
    "    def __init__(self, ordernum,samplename):\n",
    "        super(PDF, self).__init__()\n",
    "        self.ordernum = ordernum\n",
    "        self.samplename = samplename\n",
    "    def footer(self):\n",
    "        # Go to 1.5 cm from bottom\n",
    "        self.set_y(-20)\n",
    "        # Select Arial italic 8\n",
    "        self.set_font('Arial', 'I', 8)\n",
    "        # Text color in gray\n",
    "        self.set_text_color(128)\n",
    "        # Print right order-number\n",
    "        self.cell(0, 10, 'Order: '+str(self.ordernum)+' / Sample: '+str(self.samplename), 0, 0, 'R')\n",
    "\n",
    "\n",
    "today = date.today()\n",
    "analysis_date = today.strftime(\"%d.%m.%Y\")\n",
    "missingGenera = []\n",
    "sample_dir = input_dir\n",
    "for idx in df_sampleinfo.index:\n",
    "    #---------------------#\n",
    "    #-- English Version --#\n",
    "    #---------------------#\n",
    "    pdf = PDF(df_sampleinfo.loc[idx,'OrderNumber'],df_sampleinfo.loc[idx,'SampleName'])\n",
    "    pdf.alias_nb_pages()\n",
    "    pdf.add_page()\n",
    "    pdf.set_margins(left=20,right=20,top=10)\n",
    "    # Add title\n",
    "    pdf.set_font('Helvetica', 'B', 16)\n",
    "    # Title\n",
    "    pdf.cell(170, 10, 'Microbiome Analysis for Sample '+str(df_sampleinfo.loc[idx,'Screening-ID']), border =0, align='C')\n",
    "    pdf.ln(9)\n",
    "    # Sample description\n",
    "    pdf.set_font('Helvetica', '', 11)\n",
    "    pdf.rect(19,20,172,14)\n",
    "    pdf.cell(70, 10, 'Age (on collection date): '+ str(df_sampleinfo.loc[idx,'Age']), align='L', border=0)\n",
    "    try:\n",
    "        collect_date = str(datetime.strptime(df_sampleinfo.loc[idx,'SamplingDate'], '%d.%m.%y').date().strftime('%d.%m.%Y'))\n",
    "    except ValueError:\n",
    "        collect_date = df_sampleinfo.loc[idx,'SamplingDate']\n",
    "    pdf.cell(100, 10, 'Collection date: '+ collect_date, align='R', border=0)\n",
    "    pdf.ln(6)\n",
    "    pdf.cell(70, 10, 'Sample type: '+df_sampleinfo.loc[idx,'SampleType'].capitalize(), align='L', border=0)\n",
    "    pdf.cell(100, 10, 'Analysis date: '+ str(analysis_date), align='R', border=0)\n",
    "    pdf.ln(11)\n",
    "\n",
    "    # Alpha diversity: Boxplot\n",
    "    pdf.set_font('Helvetica', 'B', 11)\n",
    "    pdf.rect(19,37,101,40)\n",
    "    pdf.cell(99, 10, 'Richness analysis', align='L', border=0)\n",
    "    pdf.image(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'alpha-diversity_EN.jpg'), x=22, y=44, w=96)\n",
    "    # Conclusion\n",
    "    conclu_dict = {}\n",
    "    sname = df_sampleinfo.loc[idx,'SampleName']\n",
    "    with open(os.path.join(input_dir,sname,'report_EN.txt'),'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            conclu_dict.update({line.strip().split(':')[0]:line.strip().split(':')[1]})\n",
    "    pdf.rect(123,37,68,40)\n",
    "    pdf.cell(5)\n",
    "    pdf.cell(66, 10, 'Conclusion', align='L', border=0)\n",
    "    pdf.set_font('Helvetica', '', 9)\n",
    "    pdf.ln(10)\n",
    "    pdf.cell(105)\n",
    "    if isinstance(df_sampleinfo.loc[idx,'Age'],str):\n",
    "        pdf.multi_cell(w=64,text='Number of taxa: '+conclu_dict['std']+' of the \"Healthy young\" cohort (age < 40)',align='J') \n",
    "    else:\n",
    "        if df_sampleinfo.loc[idx,'Age'] < 40 or isinstance(df_sampleinfo.loc[idx,'Age'],str):\n",
    "            pdf.multi_cell(w=64,text='Number of taxa: '+conclu_dict['std']+' of the \"Healthy young\" cohort (age < 40)',align='J') \n",
    "        else:\n",
    "            pdf.multi_cell(w=64,text='Number of taxa: '+conclu_dict['healthy']+' of the \"Healthy old\" cohort (age > 40)',align='J')\n",
    "    pdf.ln(3)\n",
    "    pdf.cell(105)\n",
    "    x, y = pdf.x, pdf.y\n",
    "    pdf.multi_cell(w=64,\n",
    "                   text='The sample is in Cluster '+conclu_dict['cluster']+' (typical for ~'+conclu_dict['percentage']+'% of persons), distinguished by __'+conclu_dict['distinguish']+'__',\n",
    "                   align='J', markdown=True)\n",
    "    \n",
    "    pdf.ln(3)\n",
    "    pdf.cell(105)\n",
    "    x, y = pdf.x, pdf.y\n",
    "    pdf.multi_cell(w=45,text='Most abundant genus is __'+conclu_dict['topgenus']+'__',align='J',markdown=True)\n",
    "    pdf.set_font('Helvetica', 'B', 11)\n",
    "    # pdf.ln(5)\n",
    "    \n",
    "    # Tree: Phylum\n",
    "    pdf.rect(19,80,101,100)\n",
    "    pdf.set_xy(20,79)\n",
    "    pdf.cell(99, 10, 'Reference: Healthy young and old population', align='L', border=0)\n",
    "    im = Image.open(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'sampletree.png'))\n",
    "    if im.size[0]/im.size[1] < 1:\n",
    "        pdf.image(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'sampletree.png'), x=29, y= 90, h=87)\n",
    "    else:\n",
    "        pdf.image(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'sampletree.png'), x=29, y= 90, w=87)\n",
    "    pdf.image(os.path.join(ref_db,'clade_legend_EN.png'), x=20, y= 161, w=15)\n",
    "    # Phylum barplot\n",
    "    pdf.rect(123,80,68,100)\n",
    "    pdf.cell(5)\n",
    "    pdf.cell(66, 10, 'Phylum analysis', align='L', border=0)\n",
    "    pdf.image(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'phylum_EN.jpg'), x=128, y= 90, h=89)\n",
    "    pdf.image(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'f_b_ratio_EN.jpg'), x=159, y= 124, h=55)\n",
    "    pdf.ln(103)\n",
    "\n",
    "    # Top 10 genera\n",
    "    pdf.rect(19,183,172,94)\n",
    "    pdf.cell(169, 10, 'Genus analysis (Top 10 genera)', align='L', border=0)\n",
    "    pdf.image(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'genera_EN.jpg'), x=22, y= 191, h=85)\n",
    "\n",
    "    # Table with genus function\n",
    "    df_func = pd.read_csv(ref_func,sep='\\t',encoding = \"utf16\").set_index('Genus')\n",
    "    df_func = df_func[['Function']]\n",
    "    with open(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'topGenera.pkl'),'rb') as f: topGenera = pickle.load(f)        \n",
    "    commonGenera = [g for g in topGenera if g in df_func.index.to_list()]\n",
    "    commonGenera.reverse()\n",
    "    missingGenera.extend([g for g in topGenera if not g in df_func.index.to_list()])\n",
    "    df_func = df_func.loc[commonGenera,:].reset_index().map(str)\n",
    "    data = [list(df_func)] + df_func.values.tolist()  # Combine columns and rows in one list\n",
    "    pdf.ln(6)\n",
    "    headings_style = FontFace(emphasis=\"BOLD\",fill_color=(200, 200, 200))\n",
    "    pdf.set_font('Helvetica', '', 7)\n",
    "    with pdf.table(width=101, col_widths=(25,76), align='R', first_row_as_headings=True,headings_style=headings_style,line_height=1.1 * pdf.font_size) as table:\n",
    "        INDEX_OF_COLUMN_IN_ITALICS = 0\n",
    "        ITALICS = FontFace(emphasis=\"ITALICS\")\n",
    "        header = True\n",
    "        for data_row in data:\n",
    "            row = table.row()\n",
    "            for i, datum in enumerate(data_row):\n",
    "                row.cell(datum, style=ITALICS if not header and i == INDEX_OF_COLUMN_IN_ITALICS else None)\n",
    "                header = False\n",
    "\n",
    "    #----------------------#\n",
    "    #--  German Version  --#\n",
    "    #----------------------#\n",
    "    pdf.add_page()\n",
    "    pdf.set_margins(left=20,right=20,top=10)\n",
    "    # Add title\n",
    "    pdf.set_font('Helvetica', 'B', 16)\n",
    "    # Title\n",
    "    pdf.cell(170, 10, 'Mikrobiom Analyse für Probe '+str(df_sampleinfo.loc[idx,'Screening-ID']), border =0, align='C')\n",
    "    pdf.ln(9)\n",
    "    # Sample description\n",
    "    pdf.set_font('Helvetica', '', 11)\n",
    "    pdf.rect(19,20,172,14)\n",
    "    pdf.cell(70, 10, 'Alter (am Sammeltag): '+ str(df_sampleinfo.loc[idx,'Age']), align='L', border=0)\n",
    "    pdf.cell(100, 10, 'Sammeldatum: '+ collect_date, align='R', border=0)\n",
    "    pdf.ln(6)\n",
    "    sample_type = 'Stuhl' if df_sampleinfo.loc[idx,'SampleType'].lower()=='stool' else 'Unknown'\n",
    "    pdf.cell(70, 10, 'Probentyp: '+sample_type, align='L', border=0)\n",
    "    pdf.cell(100, 10, 'Analysendatum: '+ str(analysis_date), align='R', border=0)\n",
    "    pdf.ln(11)\n",
    "\n",
    "    # Alpha diversity: Boxplot\n",
    "    pdf.set_font('Helvetica', 'B', 11)\n",
    "    pdf.rect(19,37,101,40)\n",
    "    pdf.cell(99, 10, 'Analyse des Artenreichtums', align='L', border=0)\n",
    "    pdf.image(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'alpha-diversity_DE.jpg'), x=22, y=44, w=96)\n",
    "    # Conclusion\n",
    "    conclu_dict = {}\n",
    "    sname = df_sampleinfo.loc[idx,'SampleName']\n",
    "    with open(os.path.join(input_dir,sname,'report_DE.txt'),'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            conclu_dict.update({line.strip().split(':')[0]:line.strip().split(':')[1]})\n",
    "    pdf.rect(123,37,68,40)\n",
    "    pdf.cell(5)\n",
    "    pdf.cell(66, 10, 'Zusammenfassung', align='L', border=0)\n",
    "    pdf.set_font('Helvetica', '', 9)\n",
    "    pdf.ln(10)\n",
    "    pdf.cell(105)\n",
    "    if isinstance(df_sampleinfo.loc[idx,'Age'],str):\n",
    "        pdf.multi_cell(w=64,text='Anzahl der Taxa: '+conclu_dict['std']+' der Kohorte \"Gesund, jung\" (Alter < 40)',align='J') \n",
    "    else:\n",
    "        if df_sampleinfo.loc[idx,'Age'] < 40 :\n",
    "            pdf.multi_cell(w=64,text='Anzahl der Taxa: '+conclu_dict['std']+' der Kohorte \"Gesund, jung\" (Alter < 40)',align='J') \n",
    "        else:\n",
    "            pdf.multi_cell(w=64,text='Anzahl der Taxa: '+conclu_dict['healthy']+' der Kohorte \"Gesund, alt\" (Alter > 40)',align='J')\n",
    "    pdf.ln(3)\n",
    "    pdf.cell(105)\n",
    "    x, y = pdf.x, pdf.y\n",
    "    pdf.multi_cell(w=64,\n",
    "                   text='Die Probe fällt in Cluster '+conclu_dict['cluster']+' (typisch für ~'+conclu_dict['percentage']+'% der Personen), gekennzeichnet durch __'+conclu_dict['distinguish']+'__',\n",
    "                   align='J', markdown=True)\n",
    "    pdf.ln(3)\n",
    "    pdf.cell(105)\n",
    "    pdf.multi_cell(w=45,text='Die häufigste Gattung ist __'+conclu_dict['topgenus']+'__',align='J',markdown=True)\n",
    "    pdf.set_font('Helvetica', 'B', 11)\n",
    "    \n",
    "    # Tree: Phylum\n",
    "    pdf.rect(19,80,101,100)\n",
    "    pdf.set_xy(20,79)\n",
    "    pdf.cell(99, 10, 'Referenz: Gesunde, junge und alte Menschen', align='L', border=0)\n",
    "    im = Image.open(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'sampletree.png'))\n",
    "    if im.size[0]/im.size[1] < 1:\n",
    "        pdf.image(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'sampletree.png'), x=29, y= 90, h=87)\n",
    "    else:\n",
    "        pdf.image(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'sampletree.png'), x=29, y= 90, w=87)\n",
    "    pdf.image(os.path.join(ref_db,'clade_legend_DE.png'), x=20, y= 161, w=15)\n",
    "    # Phylum barplot\n",
    "    pdf.rect(123,80,68,100)\n",
    "    pdf.cell(5)\n",
    "    pdf.cell(66, 10, 'Analyse der Stämme', align='L', border=0)\n",
    "    pdf.image(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'phylum_DE.jpg'), x=128, y= 90, h=89)\n",
    "    pdf.image(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'f_b_ratio_DE.jpg'), x=159, y= 124, h=55)\n",
    "    pdf.ln(103)\n",
    "\n",
    "    # Top 10 genera\n",
    "    pdf.rect(19,183,172,94)\n",
    "    pdf.cell(169, 10, 'Analyse der Gattungen (Obere 10)', align='L', border=0)\n",
    "    pdf.image(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'genera_DE.jpg'), x=22, y= 191, h=85)\n",
    "\n",
    "    # Table with genus function\n",
    "    df_func = pd.read_csv(ref_func,sep='\\t',encoding = \"utf16\").rename(columns={'Genus':'Gattung'}).set_index('Gattung')\n",
    "    df_func = df_func[['Funktion']]\n",
    "    with open(os.path.join(input_dir,df_sampleinfo.loc[idx,'SampleName'],'topGenera.pkl'),'rb') as f: topGenera = pickle.load(f)        \n",
    "    commonGenera = [g for g in topGenera if g in df_func.index.to_list()]\n",
    "    commonGenera.reverse()\n",
    "    missingGenera.extend([g for g in topGenera if not g in df_func.index.to_list()])\n",
    "    df_func = df_func.loc[commonGenera,:].reset_index().map(str)\n",
    "    data = [list(df_func)] + df_func.values.tolist()  # Combine columns and rows in one list\n",
    "    pdf.ln(6)\n",
    "    headings_style = FontFace(emphasis=\"BOLD\",fill_color=(200, 200, 200))\n",
    "    pdf.set_font('Helvetica', '', 7)\n",
    "    with pdf.table(width=101, col_widths=(25,76), align='R', first_row_as_headings=True,headings_style=headings_style,line_height=1.1 * pdf.font_size) as table:\n",
    "        INDEX_OF_COLUMN_IN_ITALICS = 0\n",
    "        ITALICS = FontFace(emphasis=\"ITALICS\")\n",
    "        header = True\n",
    "        for data_row in data:\n",
    "            row = table.row()\n",
    "            for i, datum in enumerate(data_row):\n",
    "                row.cell(datum, style=ITALICS if not header and i == INDEX_OF_COLUMN_IN_ITALICS else None)\n",
    "                header = False\n",
    "    \n",
    "    if not os.path.exists(os.path.join(input_dir,'pdf')): os.mkdir(os.path.join(input_dir,'pdf'))\n",
    "    pdf.output(os.path.join(input_dir,'pdf',str(df_sampleinfo.loc[idx,'Screening-ID'])+'.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show missing Genera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Others'}\n"
     ]
    }
   ],
   "source": [
    "print(set(missingGenera))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indi_report",
   "language": "python",
   "name": "indi_report"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
